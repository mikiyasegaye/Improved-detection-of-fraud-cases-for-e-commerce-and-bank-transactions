{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "749e1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipaddress\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set display and plotting options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f56e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud_Data clean shape: (151112, 11)\n",
      "IpAddress_to_Country clean shape: (138846, 3)\n",
      "creditcard clean shape: (283726, 31)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned datasets\n",
    "fraud_clean = pd.read_csv('../../data/processed/Fraud_Data_clean.csv')\n",
    "ip_map_clean = pd.read_csv('../../data/processed/IpAddress_to_Country_clean.csv')\n",
    "credit_clean = pd.read_csv('../../data/processed/creditcard_clean.csv')\n",
    "\n",
    "print('Fraud_Data clean shape:', fraud_clean.shape)\n",
    "print('IpAddress_to_Country clean shape:', ip_map_clean.shape)\n",
    "print('creditcard clean shape:', credit_clean.shape)\n",
    "\n",
    "# Convert datetime columns back\n",
    "fraud_clean['signup_time'] = pd.to_datetime(fraud_clean['signup_time'])\n",
    "fraud_clean['purchase_time'] = pd.to_datetime(fraud_clean['purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9e18ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP conversion completed\n"
     ]
    }
   ],
   "source": [
    "def ip_to_int(ip_str):\n",
    "    \"\"\"Convert IP address string to integer\"\"\"\n",
    "    try:\n",
    "        return int(ipaddress.IPv4Address(ip_str))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Convert IP addresses in fraud data\n",
    "fraud_clean['ip_int'] = fraud_clean['ip_address'].astype(str).apply(ip_to_int)\n",
    "\n",
    "# Convert IP addresses in IP mapping\n",
    "ip_map_clean['lower_bound_int'] = ip_map_clean['lower_bound_ip_address'].apply(ip_to_int)\n",
    "ip_map_clean['upper_bound_int'] = ip_map_clean['upper_bound_ip_address'].apply(ip_to_int)\n",
    "\n",
    "print('IP conversion completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff329c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid IP range: 16777216.0 to 3758096383\n",
      "Original fraud data: 151112 records\n",
      "Filtered fraud data: 131095 records\n",
      "Records outside IP range: 20017\n",
      "IP conversion and filtering completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load processed data\n",
    "fraud_clean = pd.read_csv('../../data/processed/Fraud_Data_clean.csv')\n",
    "ip_map_clean = pd.read_csv('../../data/processed/IpAddress_to_Country_clean.csv')\n",
    "\n",
    "# Convert to numeric (they're already numeric, but ensure proper dtype)\n",
    "fraud_clean['ip_int'] = pd.to_numeric(fraud_clean['ip_address'], errors='coerce')\n",
    "ip_map_clean['lower_bound_int'] = pd.to_numeric(ip_map_clean['lower_bound_ip_address'], errors='coerce')\n",
    "ip_map_clean['upper_bound_int'] = pd.to_numeric(ip_map_clean['upper_bound_ip_address'], errors='coerce')\n",
    "\n",
    "# Get the valid IP range from mapping data\n",
    "min_valid_ip = ip_map_clean['lower_bound_int'].min()\n",
    "max_valid_ip = ip_map_clean['upper_bound_int'].max()\n",
    "\n",
    "print(f'Valid IP range: {min_valid_ip} to {max_valid_ip}')\n",
    "\n",
    "# Filter fraud data to only include IPs within the valid range\n",
    "fraud_filtered = fraud_clean[\n",
    "    (fraud_clean['ip_int'] >= min_valid_ip) & \n",
    "    (fraud_clean['ip_int'] <= max_valid_ip)\n",
    "].copy()\n",
    "\n",
    "print(f'Original fraud data: {fraud_clean.shape[0]} records')\n",
    "print(f'Filtered fraud data: {fraud_filtered.shape[0]} records')\n",
    "print(f'Records outside IP range: {fraud_clean.shape[0] - fraud_filtered.shape[0]}')\n",
    "\n",
    "# Remove any NaN values\n",
    "fraud_filtered = fraud_filtered.dropna(subset=['ip_int'])\n",
    "ip_map_clean = ip_map_clean.dropna(subset=['lower_bound_int', 'upper_bound_int'])\n",
    "\n",
    "print('IP conversion and filtering completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types before merge:\n",
      "fraud_sorted ip_int dtype: float64\n",
      "ip_sorted lower_bound_int dtype: float64\n",
      "Merged dataset shape: (129146, 15)\n",
      "Countries found: 181\n",
      "Sample merged data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247547</td>\n",
       "      <td>1.677886e+07</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220737</td>\n",
       "      <td>1.684205e+07</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390400</td>\n",
       "      <td>1.684366e+07</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69592</td>\n",
       "      <td>1.693873e+07</td>\n",
       "      <td>China</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174987</td>\n",
       "      <td>1.697198e+07</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    ip_address    country  class\n",
       "0   247547  1.677886e+07  Australia      0\n",
       "1   220737  1.684205e+07   Thailand      0\n",
       "2   390400  1.684366e+07      China      0\n",
       "3    69592  1.693873e+07      China      0\n",
       "4   174987  1.697198e+07   Thailand      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort both datasets by IP integer for merge_asof\n",
    "fraud_sorted = fraud_filtered.sort_values('ip_int')\n",
    "ip_sorted = ip_map_clean.sort_values('lower_bound_int')\n",
    "\n",
    "# Ensure both columns are numeric\n",
    "print('Data types before merge:')\n",
    "print('fraud_sorted ip_int dtype:', fraud_sorted['ip_int'].dtype)\n",
    "print('ip_sorted lower_bound_int dtype:', ip_sorted['lower_bound_int'].dtype)\n",
    "\n",
    "# Merge using merge_asof (for range-based matching)\n",
    "fraud_with_country = pd.merge_asof(\n",
    "    fraud_sorted,\n",
    "    ip_sorted[['lower_bound_int', 'upper_bound_int', 'country']],\n",
    "    left_on='ip_int',\n",
    "    right_on='lower_bound_int',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Filter to ensure IP is within the range\n",
    "fraud_with_country = fraud_with_country[\n",
    "    (fraud_with_country['ip_int'] >= fraud_with_country['lower_bound_int']) &\n",
    "    (fraud_with_country['ip_int'] <= fraud_with_country['upper_bound_int'])\n",
    "]\n",
    "\n",
    "print('Merged dataset shape:', fraud_with_country.shape)\n",
    "print('Countries found:', fraud_with_country['country'].nunique())\n",
    "print('Sample merged data:')\n",
    "display(fraud_with_country[['user_id', 'ip_address', 'country', 'class']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd67e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed\n",
      "New features added:\n",
      "- time_since_signup\n",
      "- hour_of_day\n",
      "- day_of_week\n",
      "- user_transaction_count\n",
      "- device_usage_count\n",
      "- ip_usage_count\n",
      "- country_transaction_count\n",
      "Final dataset shape: (129146, 23)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Feature Engineering\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Use the merged dataset\n",
    "fraud_with_features = fraud_with_country.copy()\n",
    "\n",
    "# 1. Time-based features\n",
    "fraud_with_features['signup_time'] = pd.to_datetime(fraud_with_features['signup_time'])\n",
    "fraud_with_features['purchase_time'] = pd.to_datetime(fraud_with_features['purchase_time'])\n",
    "\n",
    "# Time since signup (in hours)\n",
    "fraud_with_features['time_since_signup'] = (\n",
    "    fraud_with_features['purchase_time'] - fraud_with_features['signup_time']\n",
    ").dt.total_seconds() / 3600\n",
    "\n",
    "# Hour of day\n",
    "fraud_with_features['hour_of_day'] = fraud_with_features['purchase_time'].dt.hour\n",
    "\n",
    "# Day of week\n",
    "fraud_with_features['day_of_week'] = fraud_with_features['purchase_time'].dt.dayofweek\n",
    "\n",
    "# 2. Transaction velocity features\n",
    "# Transactions per user (group by user_id)\n",
    "user_transaction_counts = fraud_with_features.groupby('user_id').size().reset_index(name='user_transaction_count')\n",
    "fraud_with_features = fraud_with_features.merge(user_transaction_counts, on='user_id', how='left')\n",
    "\n",
    "# 3. Device and IP usage patterns\n",
    "device_counts = fraud_with_features.groupby('device_id').size().reset_index(name='device_usage_count')\n",
    "fraud_with_features = fraud_with_features.merge(device_counts, on='device_id', how='left')\n",
    "\n",
    "ip_counts = fraud_with_features.groupby('ip_address').size().reset_index(name='ip_usage_count')\n",
    "fraud_with_features = fraud_with_features.merge(ip_counts, on='ip_address', how='left')\n",
    "\n",
    "# 4. Country-based features\n",
    "country_counts = fraud_with_features.groupby('country').size().reset_index(name='country_transaction_count')\n",
    "fraud_with_features = fraud_with_features.merge(country_counts, on='country', how='left')\n",
    "\n",
    "print('Feature engineering completed')\n",
    "print('New features added:')\n",
    "print('- time_since_signup')\n",
    "print('- hour_of_day') \n",
    "print('- day_of_week')\n",
    "print('- user_transaction_count')\n",
    "print('- device_usage_count')\n",
    "print('- ip_usage_count')\n",
    "print('- country_transaction_count')\n",
    "\n",
    "print(f'Final dataset shape: {fraud_with_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba2dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (129146, 13)\n",
      "Target shape: (129146,)\n",
      "Class distribution:\n",
      "class\n",
      "0    0.905007\n",
      "1    0.094993\n",
      "Name: proportion, dtype: float64\n",
      "Training set shape: (103316, 13)\n",
      "Test set shape: (25830, 13)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Data Transformation\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Categorical encoding\n",
    "categorical_columns = ['source', 'browser', 'sex', 'country']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in fraud_with_features.columns:\n",
    "        le = LabelEncoder()\n",
    "        fraud_with_features[f'{col}_encoded'] = le.fit_transform(fraud_with_features[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# 2. Select features for modeling\n",
    "feature_columns = [\n",
    "    'purchase_value', 'age', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'user_transaction_count', 'device_usage_count', 'ip_usage_count', 'country_transaction_count',\n",
    "    'source_encoded', 'browser_encoded', 'sex_encoded', 'country_encoded'\n",
    "]\n",
    "\n",
    "# Remove rows with missing values in features\n",
    "fraud_with_features = fraud_with_features.dropna(subset=feature_columns + ['class'])\n",
    "\n",
    "# 3. Prepare X and y\n",
    "X = fraud_with_features[feature_columns]\n",
    "y = fraud_with_features['class']\n",
    "\n",
    "print(f'Features shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')\n",
    "print(f'Class distribution:')\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# 4. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set shape: {X_train_scaled.shape}')\n",
    "print(f'Test set shape: {X_test_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d660107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set class distribution:\n",
      "class\n",
      "0    0.90501\n",
      "1    0.09499\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "After SMOTE:\n",
      "class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "After Random Undersampling:\n",
      "class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Processed data saved to: ../../data/processed/fraud_data_with_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Handle Class Imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "print('Original training set class distribution:')\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "# Option 1: SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print('\\nAfter SMOTE:')\n",
    "print(pd.Series(y_train_smote).value_counts(normalize=True))\n",
    "\n",
    "# Option 2: Random Undersampling (for comparison)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print('\\nAfter Random Undersampling:')\n",
    "print(pd.Series(y_train_rus).value_counts(normalize=True))\n",
    "\n",
    "# Save processed data\n",
    "fraud_with_features.to_csv('../../data/processed/fraud_data_with_features.csv', index=False)\n",
    "print('\\nProcessed data saved to: ../../data/processed/fraud_data_with_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
