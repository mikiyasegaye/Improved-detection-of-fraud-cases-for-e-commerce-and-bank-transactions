{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec13f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_recall_curve, average_precision_score,\n",
    "    roc_auc_score, f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display and plotting options\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3e43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud_Data shape: (129146, 27)\n",
      "Credit card data shape: (283726, 31)\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "fraud_data = pd.read_csv('../../data/processed/fraud_data_with_features.csv')\n",
    "credit_data = pd.read_csv('../../data/processed/creditcard_clean.csv')\n",
    "\n",
    "print('Fraud_Data shape:', fraud_data.shape)\n",
    "print('Credit card data shape:', credit_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92c1d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud_Data features shape: (129146, 13)\n",
      "Fraud_Data target shape: (129146,)\n",
      "Fraud_Data class distribution:\n",
      "class\n",
      "0    0.905007\n",
      "1    0.094993\n",
      "Name: proportion, dtype: float64\n",
      "Credit card features shape: (283726, 29)\n",
      "Credit card target shape: (283726,)\n",
      "Credit card class distribution:\n",
      "Class\n",
      "0    0.998333\n",
      "1    0.001667\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fraud_Data features\n",
    "fraud_feature_columns = [\n",
    "    'purchase_value', 'age', 'time_since_signup', 'hour_of_day', 'day_of_week',\n",
    "    'user_transaction_count', 'device_usage_count', 'ip_usage_count', 'country_transaction_count',\n",
    "    'source_encoded', 'browser_encoded', 'sex_encoded', 'country_encoded'\n",
    "]\n",
    "fraud_data_clean = fraud_data.dropna(subset=fraud_feature_columns + ['class'])\n",
    "X_fraud = fraud_data_clean[fraud_feature_columns]\n",
    "y_fraud = fraud_data_clean['class']\n",
    "print('Fraud_Data features shape:', X_fraud.shape)\n",
    "print('Fraud_Data target shape:', y_fraud.shape)\n",
    "print('Fraud_Data class distribution:')\n",
    "print(y_fraud.value_counts(normalize=True))\n",
    "\n",
    "# Credit card features\n",
    "credit_feature_columns = [col for col in credit_data.columns if col not in ['Time', 'Class']]\n",
    "X_credit = credit_data[credit_feature_columns]\n",
    "y_credit = credit_data['Class']\n",
    "print('Credit card features shape:', X_credit.shape)\n",
    "print('Credit card target shape:', y_credit.shape)\n",
    "print('Credit card class distribution:')\n",
    "print(y_credit.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917636e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud_Data - Training set shape: (187004, 13)\n",
      "Fraud_Data - Test set shape: (25830, 13)\n",
      "Fraud_Data - Balanced training class distribution:\n",
      "class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Credit card - Training set shape: (453204, 29)\n",
      "Credit card - Test set shape: (56746, 29)\n",
      "Credit card - Balanced training class distribution:\n",
      "Class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fraud_Data\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "scaler_fraud = StandardScaler()\n",
    "X_fraud_train_scaled = scaler_fraud.fit_transform(X_fraud_train)\n",
    "X_fraud_test_scaled = scaler_fraud.transform(X_fraud_test)\n",
    "smote_fraud = SMOTE(random_state=42)\n",
    "X_fraud_train_balanced, y_fraud_train_balanced = smote_fraud.fit_resample(X_fraud_train_scaled, y_fraud_train)\n",
    "print('Fraud_Data - Training set shape:', X_fraud_train_balanced.shape)\n",
    "print('Fraud_Data - Test set shape:', X_fraud_test_scaled.shape)\n",
    "print('Fraud_Data - Balanced training class distribution:')\n",
    "print(pd.Series(y_fraud_train_balanced).value_counts(normalize=True))\n",
    "\n",
    "# Credit card\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(\n",
    "    X_credit, y_credit, test_size=0.2, random_state=42, stratify=y_credit\n",
    ")\n",
    "scaler_credit = StandardScaler()\n",
    "X_credit_train_scaled = scaler_credit.fit_transform(X_credit_train)\n",
    "X_credit_test_scaled = scaler_credit.transform(X_credit_test)\n",
    "smote_credit = SMOTE(random_state=42)\n",
    "X_credit_train_balanced, y_credit_train_balanced = smote_credit.fit_resample(X_credit_train_scaled, y_credit_train)\n",
    "print('Credit card - Training set shape:', X_credit_train_balanced.shape)\n",
    "print('Credit card - Test set shape:', X_credit_test_scaled.shape)\n",
    "print('Credit card - Balanced training class distribution:')\n",
    "print(pd.Series(y_credit_train_balanced).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809d601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name, dataset_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'\\n{model_name} on {dataset_name}:')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "    print(f'AUC-PR: {auc_pr:.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    return {'model': model, 'f1_score': f1, 'auc_pr': auc_pr, 'confusion_matrix': cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d490f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression on Fraud_Data:\n",
      "F1-Score: 0.6243\n",
      "AUC-PR: 0.6590\n",
      "Confusion Matrix:\n",
      "[[21998  1378]\n",
      " [  715  1739]]\n",
      "\n",
      "Random Forest on Fraud_Data:\n",
      "F1-Score: 0.6988\n",
      "AUC-PR: 0.7085\n",
      "Confusion Matrix:\n",
      "[[23277    99]\n",
      " [ 1083  1371]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on Fraud_Data\n",
    "fraud_results = {}\n",
    "for name, model in models.items():\n",
    "    results = evaluate_model(\n",
    "        model, X_fraud_train_balanced, y_fraud_train_balanced, X_fraud_test_scaled, y_fraud_test, name, 'Fraud_Data'\n",
    "    )\n",
    "    fraud_results[name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846dcf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression on creditcard:\n",
      "F1-Score: 0.0993\n",
      "AUC-PR: 0.6763\n",
      "Confusion Matrix:\n",
      "[[55158  1493]\n",
      " [   12    83]]\n",
      "\n",
      "Random Forest on creditcard:\n",
      "F1-Score: 0.8202\n",
      "AUC-PR: 0.8110\n",
      "Confusion Matrix:\n",
      "[[56641    10]\n",
      " [   22    73]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models on creditcard data\n",
    "credit_results = {}\n",
    "for name, model in models.items():\n",
    "    results = evaluate_model(\n",
    "        model, X_credit_train_balanced, y_credit_train_balanced, X_credit_test_scaled, y_credit_test, name, 'creditcard'\n",
    "    )\n",
    "    credit_results[name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9053ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "      Dataset                Model  F1-Score    AUC-PR\n",
      "0  Fraud_Data  Logistic Regression  0.624304  0.658970\n",
      "1  Fraud_Data        Random Forest  0.698777  0.708472\n",
      "2  creditcard  Logistic Regression  0.099342  0.676257\n",
      "3  creditcard        Random Forest  0.820225  0.811033\n",
      "\n",
      "Fraud_Data:\n",
      "Best F1-Score: Random Forest (0.6988)\n",
      "Best AUC-PR: Random Forest (0.7085)\n",
      "\n",
      "creditcard:\n",
      "Best F1-Score: Random Forest (0.8202)\n",
      "Best AUC-PR: Random Forest (0.8110)\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "comparison_data = []\n",
    "for dataset_name, results in [('Fraud_Data', fraud_results), ('creditcard', credit_results)]:\n",
    "    for model_name, result in results.items():\n",
    "        comparison_data.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Model': model_name,\n",
    "            'F1-Score': result['f1_score'],\n",
    "            'AUC-PR': result['auc_pr']\n",
    "        })\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print('Model Performance Comparison:')\n",
    "print(comparison_df)\n",
    "\n",
    "# Select best model for each dataset\n",
    "for dataset in ['Fraud_Data', 'creditcard']:\n",
    "    dataset_results = comparison_df[comparison_df['Dataset'] == dataset]\n",
    "    best_f1_idx = dataset_results['F1-Score'].idxmax()\n",
    "    best_auc_idx = dataset_results['AUC-PR'].idxmax()\n",
    "    print(f'\\n{dataset}:')\n",
    "    print(f'Best F1-Score: {dataset_results.loc[best_f1_idx, \"Model\"]} ({dataset_results.loc[best_f1_idx, \"F1-Score\"]:.4f})')\n",
    "    print(f'Best AUC-PR: {dataset_results.loc[best_auc_idx, \"Model\"]} ({dataset_results.loc[best_auc_idx, \"AUC-PR\"]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa32718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models saved to models/ directory\n"
     ]
    }
   ],
   "source": [
    "# Save best models\n",
    "best_fraud_model = fraud_results['Random Forest']['model']  # Change if Logistic Regression is better\n",
    "best_credit_model = credit_results['Random Forest']['model']  # Change if Logistic Regression is better\n",
    "joblib.dump(best_fraud_model, '../../models/best_fraud_model.pkl')\n",
    "joblib.dump(best_credit_model, '../../models/best_credit_model.pkl')\n",
    "print('Best models saved to models/ directory')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
